{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9455831",
   "metadata": {},
   "source": [
    "## Make a list of all of the filenames you want to open\n",
    "\n",
    "You _could_ do this manually, but I suggest using my favorite-named tool: **glob**! It works like this:\n",
    "\n",
    "```python\n",
    "# Get a list of all CSV files in the current directory \n",
    "# that start with \"sales,\" e.g. sales-2020.csv, sales-2015.csv, etc\n",
    "import glob\n",
    "filenames = glob.glob(\"sales-*.csv\")\n",
    "```\n",
    "\n",
    "* _**Tip:** `*` means \"match anything.\" _It's different than the `.*` we used in class, but it's the same idea._\n",
    "* _**Tip:** Make sure your list includes both 2015 *and* 2019. Remember, some are `xls` and some are `xlsx`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e3bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cf7c6b9",
   "metadata": {},
   "source": [
    "## Open one of them with pandas just to test it out. Any of them!\n",
    "\n",
    "You'll need to use `skiprows=` to skip the first few rows, as they're informational and not actual data.\n",
    "\n",
    "* _**Tip:** Yes, the column names are awful right now, but you'll fix them later_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a202d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ded1d8b7",
   "metadata": {},
   "source": [
    "## Now open another one.\n",
    "\n",
    "Keep opening them with the same `.read_excel` options until you find one with bad headers. **UGH!!!** They all have different `skiprows=` values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b61871d",
   "metadata": {},
   "source": [
    "## Ignoring headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7cfa1",
   "metadata": {},
   "source": [
    "We're going to fix this by getting rid of `skiprows=` and using `header=None`. That way NONE of them will have ANY headers.\n",
    "\n",
    "Try `header=None` on one of them.\n",
    "\n",
    "(After we combine them all we'll update them with the right header rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1afa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6209b13e",
   "metadata": {},
   "source": [
    "## Open them all at the same time!\n",
    "\n",
    "Starting from your list of filenames, use a list comprehension (similar to how we did with the Excel sheets) to create a list of dataframes.\n",
    "\n",
    "You'll probably want to cut and paste your `.read_excel` from above so that none of them come in with headers. We'll add them in later!\n",
    "\n",
    "* _**Tip:** Make sure you have 15 years of data (aka fifteen years of dataframes)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3a1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131085e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dd45971",
   "metadata": {},
   "source": [
    "## Combine them with `pd.concat`\n",
    "\n",
    "Confirm that you should have 35,8054 rows and 21 columns. If your numbers are a *little* off you probably didn't ignore headers! (In which case, go back and do that.)\n",
    "\n",
    "Your headers should just be numbers - 0, 1, 2, 3, 4.... etc.\n",
    "\n",
    "* _**Tip:** Be sure to `ignore_index=True`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e518c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215b32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08d00fc9",
   "metadata": {},
   "source": [
    "## Add in the headers\n",
    "\n",
    "The fourth row seems to be the headers. You can update the headers to be the info from the 4rd row.\n",
    "\n",
    "```python\n",
    "df.columns = df.loc[3].tolist()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012d0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd17d740",
   "metadata": {},
   "source": [
    "## Remove the notation rows from the top of the Excel sheets\n",
    "\n",
    "We used `dropna` in class on Monday to remove rows that were missing a `Treatment Date`. Let's do the same thing here to help remove some of the garbage - it seems like we can probably rely on `NEIGHBORHOOD` or `BLOCK` missing to mean that it's a garbage row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46b6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f8d5ee4",
   "metadata": {},
   "source": [
    "Confirm that you have **357992** rows remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a11f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86bf3cf",
   "metadata": {},
   "source": [
    "## Clean up the data, then remove the duplicated header rows\n",
    "\n",
    "Every Excel sheet brought in a new 'BOROUGH' and 'NEIGHBORHOOD', etc, that were supposed to be headers.\n",
    "\n",
    "Let's look at `df.BOROUGH`. Do a `value_counts()` to see whether you notice anything unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b8fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f178aa",
   "metadata": {},
   "source": [
    "Looks like there's all sorts of spaces or newlines â€“ instead of `3` sometimes it's `3 ` (and probably other garbage like that). In theory we could get rid of it easily using `.str.strip()`, which removes whitespace from before/after a string.\n",
    "\n",
    "```python\n",
    "df.BOROUGH = df.BOROUGH.str.strip()\n",
    "```\n",
    "\n",
    "The problem is this is probably a problem in *all of the columns*. [This StackOverflow answer sets you up with a pretty good option,](https://stackoverflow.com/a/45270483) but it doesn't work in some edge cases. And of course our dataset is one of them! So try this out:\n",
    "\n",
    "```python\n",
    "df = df.apply(lambda col: col.astype(str).str.strip())\n",
    "```\n",
    "\n",
    "`.apply` is like a for loop for pandas - this loops through every column and runs `.str.strip()` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec5aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff982d6",
   "metadata": {},
   "source": [
    "Try your `value_counts()` again and let's see if it worked! It should look something like this:\n",
    "\n",
    "```\n",
    "3          72140\n",
    "BOROUGH       15\n",
    "Name: BOROUGH, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd22521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce9550a7",
   "metadata": {},
   "source": [
    "*Now* we can finally remove all of the rows where the column `df.BOROUGH` is the string `\"BOROUGH\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b45a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6938df64",
   "metadata": {},
   "source": [
    "Confirm you now have **357,977 rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109b1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ded5d3d",
   "metadata": {},
   "source": [
    "## Save the cleaned file\n",
    "\n",
    "It's good practice to save your cleaned data before you start your analysis. Use `.to_csv` to save the cleaned data, passing `index=False` so it doesn't save the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961bd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
